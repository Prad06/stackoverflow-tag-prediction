{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "import scipy.sparse\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the data\n",
    "df_javascript = pd.read_csv(\"~/project--eece7205/data/QueryResults_JS.csv\")\n",
    "df_cplusplus = pd.read_csv(\"~/project--eece7205/data/QueryResults_cplusplus.csv\")\n",
    "df_python = pd.read_csv(\"~/project--eece7205/data/QueryResults_Python.csv\")\n",
    "df_sql = pd.read_csv(\"~/project--eece7205/data/QueryResults_SQL.csv\")\n",
    "df_java = pd.read_csv(\"~/project--eece7205/data/QueryResults_Java.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_add_labels(*args):\n",
    "    labeled_dfs = [(df.assign(Label=label)) for df, label in args]\n",
    "    return pd.concat(labeled_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled = merge_add_labels(\n",
    "    (df_javascript, \"JavaScript\"),\n",
    "    (df_cplusplus, \"CPP\"),\n",
    "    (df_python, \"Python\"),\n",
    "    (df_sql, \"SQL\"),\n",
    "    (df_java, \"Java\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    text = word_tokenize(text.lower())\n",
    "    text = [\n",
    "        WordNetLemmatizer().lemmatize(word)\n",
    "        for word in text\n",
    "        if word not in stopwords.words(\"english\")\n",
    "    ]\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled[\"Processed_Text\"] = df_labeled[\"Title\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF transformation\n",
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(df_labeled[\"Processed_Text\"])\n",
    "y = df_labeled[\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned_sep = df_labeled[[\"Title\", \"Label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How can I remove a specific item from an array...</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How do I check if an element is hidden in jQuery?</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What does \"use strict\" do in JavaScript, and w...</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How do I redirect to another webpage?</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>var functionName = function() {} vs function f...</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>Get HTTP code from org.apache.http.HttpResponse</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>Which artifact for org.springframework.mail?</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>Foreign key constraints in Android using SQLit...</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>What is Stateless Object in Java?</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>Java: accessing private constructor with type ...</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Title       Label\n",
       "0      How can I remove a specific item from an array...  JavaScript\n",
       "1      How do I check if an element is hidden in jQuery?  JavaScript\n",
       "2      What does \"use strict\" do in JavaScript, and w...  JavaScript\n",
       "3                  How do I redirect to another webpage?  JavaScript\n",
       "4      var functionName = function() {} vs function f...  JavaScript\n",
       "...                                                  ...         ...\n",
       "24995    Get HTTP code from org.apache.http.HttpResponse        Java\n",
       "24996       Which artifact for org.springframework.mail?        Java\n",
       "24997  Foreign key constraints in Android using SQLit...        Java\n",
       "24998                  What is Stateless Object in Java?        Java\n",
       "24999  Java: accessing private constructor with type ...        Java\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned_sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned_sep.to_csv('~/project--eece7205/data/df_cleaned_sep_labeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 11241)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticRegressionOut(X, y, save_path='lr.joblib'):\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(df_labeled[\"Label\"])\n",
    "\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # Train the Logistic Regression model\n",
    "    model = LogisticRegression(\n",
    "        solver=\"saga\",\n",
    "        multi_class=\"multinomial\",\n",
    "        penalty='l2',\n",
    "        max_iter=1000,\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions and evaluation\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\n",
    "        \"\\nClassification Report:\\n\",\n",
    "        classification_report(y_test, y_pred, target_names=label_encoder.classes_),\n",
    "    )\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=label_encoder.classes_,\n",
    "        yticklabels=label_encoder.classes_,\n",
    "    )\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "    # Save the model\n",
    "    if save_path:\n",
    "        joblib.dump(\n",
    "            {\"model\": model, \"label_encoder\": label_encoder, \"tfidf\": tfidf}, save_path\n",
    "        )\n",
    "        print(f\"Model saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         CPP       0.71      0.88      0.79      1000\n",
      "        Java       0.87      0.80      0.83      1000\n",
      "  JavaScript       0.88      0.85      0.86      1000\n",
      "      Python       0.86      0.80      0.83      1000\n",
      "         SQL       0.94      0.90      0.92      1000\n",
      "\n",
      "    accuracy                           0.84      5000\n",
      "   macro avg       0.85      0.84      0.85      5000\n",
      "weighted avg       0.85      0.84      0.85      5000\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to lr.joblib\n"
     ]
    }
   ],
   "source": [
    "logisticRegressionOut(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/choudhari.pra/project--eece7205/models\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = os.path.expanduser('~/project--eece7205/models')\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomForestOut(X, y, save_path='randomforest.joblib'):\n",
    "    # Encode labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(y)\n",
    "    \n",
    "    # Convert y to numpy array if it's not already\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Initialize lists for storing performance metrics\n",
    "    tree_sizes = [50, 150, 250, 350, 450]\n",
    "    test_errors = []\n",
    "    train_errors = []\n",
    "    f1_scores = []\n",
    "    auc_scores = []\n",
    "    imp_features = []\n",
    "    \n",
    "    # Setup K-Fold cross validation\n",
    "    kf = KFold(n_splits=10, shuffle=True)\n",
    "    \n",
    "    # Train and evaluate models with different tree sizes\n",
    "    for tree_size in tree_sizes:\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=tree_size,\n",
    "            n_jobs=-1,\n",
    "            random_state=42,\n",
    "            bootstrap=True,\n",
    "            oob_score=True,\n",
    "            max_depth=20,\n",
    "            max_features=0.01\n",
    "        )\n",
    "        \n",
    "        # K-Fold Cross Validation\n",
    "        kf_errors = []\n",
    "        for train_ind, val_ind in kf.split(X_train):\n",
    "            # Handle both sparse and dense matrices\n",
    "            if scipy.sparse.issparse(X_train):\n",
    "                X_train_kf = X_train[train_ind]\n",
    "                X_val = X_train[val_ind]\n",
    "            else:\n",
    "                X_train_kf = X_train.iloc[train_ind]\n",
    "                X_val = X_train.iloc[val_ind]\n",
    "            \n",
    "            y_train_kf = y_train[train_ind]\n",
    "            y_val = y_train[val_ind]\n",
    "            \n",
    "            model.fit(X_train_kf, y_train_kf)\n",
    "            y_pred_val = model.predict(X_val)\n",
    "            kf_error = 1 - accuracy_score(y_val, y_pred_val)\n",
    "            kf_errors.append(kf_error)\n",
    "        \n",
    "        # Fit the model on full training data\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Calculate performance metrics\n",
    "        y_pred = model.predict(X_test)\n",
    "        test_error = 1 - accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        \n",
    "        # For multi-class, we need to use different approach for ROC AUC\n",
    "        y_pred_proba = model.predict_proba(X_test)\n",
    "        auc_score = roc_auc_score(y_test, y_pred_proba, multi_class='ovr')\n",
    "        \n",
    "        # Store metrics\n",
    "        test_errors.append(test_error)\n",
    "        train_errors.append(np.mean(kf_errors))\n",
    "        f1_scores.append(f1)\n",
    "        auc_scores.append(auc_score)\n",
    "        \n",
    "        # Get feature importances\n",
    "        feature_importances = model.feature_importances_\n",
    "        indices = np.argsort(feature_importances)[::-1]\n",
    "        imp_features.append(indices[:10])\n",
    "    \n",
    "    # Print classification report for the final model\n",
    "    print(\n",
    "        \"\\nClassification Report:\\n\",\n",
    "        classification_report(y_test, y_pred, target_names=label_encoder.classes_)\n",
    "    )\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=label_encoder.classes_,\n",
    "        yticklabels=label_encoder.classes_\n",
    "    )\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot error metrics\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(tree_sizes, test_errors, label=\"Test error\")\n",
    "    plt.plot(tree_sizes, train_errors, label=\"Train error\")\n",
    "    plt.plot(tree_sizes, f1_scores, label=\"F1 score\")\n",
    "    plt.plot(tree_sizes, auc_scores, label=\"ROC AUC\")\n",
    "    plt.xlabel(\"Number of Trees\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.title(\"Model Performance vs Number of Trees\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Save the model\n",
    "    if save_path:\n",
    "        joblib.dump(\n",
    "            {\n",
    "                \"model\": model,\n",
    "                \"label_encoder\": label_encoder,\n",
    "                \"feature_importances\": feature_importances\n",
    "            },\n",
    "            save_path\n",
    "        )\n",
    "        print(f\"Model saved to {save_path}\")\n",
    "    \n",
    "    return model, label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomForestOut(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svmOut(X, y, save_path='svm.joblib'):\n",
    "    \"\"\"\n",
    "    Trains and evaluates an SVM classifier with a single optimized configuration.\n",
    "    \n",
    "    Parameters:\n",
    "    X : feature matrix (can be sparse or dense)\n",
    "    y : target labels\n",
    "    save_path : optional path to save the model\n",
    "    \"\"\"\n",
    "    # Encode labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(y)\n",
    "    \n",
    "    # Convert y to numpy array if it's not already\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Initialize model with optimized configuration\n",
    "    model = SVC(\n",
    "        kernel='rbf',  # RBF kernel generally performs well\n",
    "        C=1.0,        # Good default value\n",
    "        probability=True,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Setup K-Fold cross validation\n",
    "    kf = KFold(n_splits=5, shuffle=True)  # Reduced from 10 to 5 folds\n",
    "    \n",
    "    # K-Fold Cross Validation\n",
    "    kf_errors = []\n",
    "    for train_ind, val_ind in kf.split(X_train):\n",
    "        # Handle both sparse and dense matrices\n",
    "        if scipy.sparse.issparse(X_train):\n",
    "            X_train_kf = X_train[train_ind]\n",
    "            X_val = X_train[val_ind]\n",
    "        else:\n",
    "            X_train_kf = X_train.iloc[train_ind]\n",
    "            X_val = X_train.iloc[val_ind]\n",
    "        \n",
    "        y_train_kf = y_train[train_ind]\n",
    "        y_val = y_train[val_ind]\n",
    "        \n",
    "        model.fit(X_train_kf, y_train_kf)\n",
    "        y_pred_val = model.predict(X_val)\n",
    "        kf_error = 1 - accuracy_score(y_val, y_pred_val)\n",
    "        kf_errors.append(kf_error)\n",
    "    \n",
    "    # Fit the model on full training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    y_pred = model.predict(X_test)\n",
    "    test_error = 1 - accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    y_pred_proba = model.predict_proba(X_test)\n",
    "    auc_score = roc_auc_score(y_test, y_pred_proba, multi_class='ovr')\n",
    "    \n",
    "    # Print performance metrics\n",
    "    print(\"\\nPerformance Metrics:\")\n",
    "    print(f\"Test Error: {test_error:.4f}\")\n",
    "    print(f\"Cross-validation Error: {np.mean(kf_errors):.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"AUC Score: {auc_score:.4f}\")\n",
    "    \n",
    "    # Print classification report\n",
    "    print(\n",
    "        \"\\nClassification Report:\\n\",\n",
    "        classification_report(y_test, y_pred, target_names=label_encoder.classes_)\n",
    "    )\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=label_encoder.classes_,\n",
    "        yticklabels=label_encoder.classes_\n",
    "    )\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Save the model\n",
    "    if save_path:\n",
    "        joblib.dump(\n",
    "            {\n",
    "                \"model\": model,\n",
    "                \"label_encoder\": label_encoder\n",
    "            },\n",
    "            save_path\n",
    "        )\n",
    "        print(f\"Model saved to {save_path}\")\n",
    "    \n",
    "    return model, label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmOut(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "class CustomNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(CustomNN, self).__init__()\n",
    "        \n",
    "        # Define architecture\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_size, hidden_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_size // 2, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Initialize weights randomly\n",
    "        self.apply(self._init_weights)\n",
    "    \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                nn.init.zeros_(module.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "def neuralNetOut(X, y, save_path='nn.joblib', epochs=100, batch_size=32, learning_rate=0.001, hidden_size=128):\n",
    "    \"\"\"\n",
    "    Train and evaluate a neural network with cross-validation\n",
    "    \"\"\"\n",
    "    # Convert data to numpy if it's sparse\n",
    "    if scipy.sparse.issparse(X):\n",
    "        X = X.toarray()\n",
    "    \n",
    "    # Encode labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(y)\n",
    "    num_classes = len(label_encoder.classes_)\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Convert to PyTorch tensors\n",
    "    X_tensor = torch.FloatTensor(X_scaled)\n",
    "    y_tensor = torch.LongTensor(y)\n",
    "    \n",
    "    # Setup k-fold cross validation\n",
    "    k_folds = 5\n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Store results\n",
    "    fold_results = []\n",
    "    best_model = None\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    # For plotting\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    # Cross validation loop\n",
    "    for fold, (train_ids, val_ids) in enumerate(kfold.split(X_tensor)):\n",
    "        print(f'\\nFOLD {fold+1}/{k_folds}')\n",
    "        \n",
    "        # Sample data for this fold\n",
    "        X_train_fold = X_tensor[train_ids]\n",
    "        y_train_fold = y_tensor[train_ids]\n",
    "        X_val_fold = X_tensor[val_ids]\n",
    "        y_val_fold = y_tensor[val_ids]\n",
    "        \n",
    "        # Create data loaders\n",
    "        train_dataset = TensorDataset(X_train_fold, y_train_fold)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        # Initialize model\n",
    "        model = CustomNN(input_size=X.shape[1], hidden_size=hidden_size, num_classes=num_classes)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "        \n",
    "        # Training loop\n",
    "        fold_train_losses = []\n",
    "        fold_val_losses = []\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            total_train_loss = 0\n",
    "            for batch_X, batch_y in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(batch_X)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_train_loss += loss.item()\n",
    "            \n",
    "            # Validation\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_outputs = model(X_val_fold)\n",
    "                val_loss = criterion(val_outputs, y_val_fold)\n",
    "                val_pred = torch.argmax(val_outputs, dim=1)\n",
    "                accuracy = accuracy_score(y_val_fold, val_pred)\n",
    "            \n",
    "            # Store losses\n",
    "            avg_train_loss = total_train_loss / len(train_loader)\n",
    "            fold_train_losses.append(avg_train_loss)\n",
    "            fold_val_losses.append(val_loss.item())\n",
    "            \n",
    "            # Scheduler step\n",
    "            scheduler.step(val_loss)\n",
    "            \n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                print(f'Epoch {epoch+1}/{epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {val_loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "        \n",
    "        # Store fold results\n",
    "        fold_results.append(accuracy)\n",
    "        \n",
    "        # Update best model\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_model = model.state_dict()\n",
    "        \n",
    "        train_losses.append(fold_train_losses)\n",
    "        val_losses.append(fold_val_losses)\n",
    "    \n",
    "    print('\\nCross-validation Results:')\n",
    "    for fold, accuracy in enumerate(fold_results):\n",
    "        print(f'Fold {fold+1}: {accuracy:.4f}')\n",
    "    print(f'Average accuracy: {np.mean(fold_results):.4f} Â± {np.std(fold_results):.4f}')\n",
    "    \n",
    "    # Create final model with best weights\n",
    "    final_model = CustomNN(input_size=X.shape[1], hidden_size=hidden_size, num_classes=num_classes)\n",
    "    final_model.load_state_dict(best_model)\n",
    "    \n",
    "    # Final evaluation\n",
    "    final_model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = torch.argmax(final_model(X_tensor), dim=1).numpy()\n",
    "    \n",
    "    # Print final report\n",
    "    print('\\nFinal Classification Report:')\n",
    "    print(classification_report(y, y_pred, target_names=label_encoder.classes_))\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=label_encoder.classes_,\n",
    "                yticklabels=label_encoder.classes_)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot training curves\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    for fold in range(k_folds):\n",
    "        plt.plot(train_losses[fold], label=f'Fold {fold+1}')\n",
    "    plt.title('Training Loss per Fold')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    for fold in range(k_folds):\n",
    "        plt.plot(val_losses[fold], label=f'Fold {fold+1}')\n",
    "    plt.title('Validation Loss per Fold')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Save the model\n",
    "    if save_path:\n",
    "        torch.save({\n",
    "            'model_state_dict': final_model.state_dict(),\n",
    "            'scaler': scaler,\n",
    "            'label_encoder': label_encoder,\n",
    "            'model_config': {\n",
    "                'input_size': X.shape[1],\n",
    "                'hidden_size': hidden_size,\n",
    "                'num_classes': num_classes\n",
    "            }\n",
    "        }, save_path)\n",
    "        print(f'\\nModel saved to {save_path}')\n",
    "    \n",
    "    return final_model, scaler, label_encoder\n",
    "\n",
    "# Function to make predictions\n",
    "def predict_with_nn(X, model_path):\n",
    "    \"\"\"\n",
    "    Make predictions using the saved neural network model\n",
    "    \"\"\"\n",
    "    # Load saved model and objects\n",
    "    checkpoint = torch.load(model_path)\n",
    "    \n",
    "    # Initialize model with saved configuration\n",
    "    model = CustomNN(\n",
    "        input_size=checkpoint['model_config']['input_size'],\n",
    "        hidden_size=checkpoint['model_config']['hidden_size'],\n",
    "        num_classes=checkpoint['model_config']['num_classes']\n",
    "    )\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    # Preprocess input\n",
    "    X_scaled = checkpoint['scaler'].transform(X)\n",
    "    X_tensor = torch.FloatTensor(X_scaled)\n",
    "    \n",
    "    # Make predictions\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_tensor)\n",
    "        predictions = torch.argmax(outputs, dim=1).numpy()\n",
    "    \n",
    "    # Convert back to original labels\n",
    "    original_labels = checkpoint['label_encoder'].inverse_transform(predictions)\n",
    "    \n",
    "    return original_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuralNetOut(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distil BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(43816) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/pradnyeshchoudhari/EECE 7205 - LOCAL/Project/eece7205/lib/python3.8/site-packages (4.46.1)\n",
      "Requirement already satisfied: filelock in /Users/pradnyeshchoudhari/EECE 7205 - LOCAL/Project/eece7205/lib/python3.8/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/pradnyeshchoudhari/EECE 7205 - LOCAL/Project/eece7205/lib/python3.8/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/pradnyeshchoudhari/EECE 7205 - LOCAL/Project/eece7205/lib/python3.8/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: requests in /Users/pradnyeshchoudhari/EECE 7205 - LOCAL/Project/eece7205/lib/python3.8/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/pradnyeshchoudhari/EECE 7205 - LOCAL/Project/eece7205/lib/python3.8/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /Users/pradnyeshchoudhari/EECE 7205 - LOCAL/Project/eece7205/lib/python3.8/site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /Users/pradnyeshchoudhari/EECE 7205 - LOCAL/Project/eece7205/lib/python3.8/site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/pradnyeshchoudhari/EECE 7205 - LOCAL/Project/eece7205/lib/python3.8/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/pradnyeshchoudhari/EECE 7205 - LOCAL/Project/eece7205/lib/python3.8/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/pradnyeshchoudhari/EECE 7205 - LOCAL/Project/eece7205/lib/python3.8/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/pradnyeshchoudhari/EECE 7205 - LOCAL/Project/eece7205/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/pradnyeshchoudhari/EECE 7205 - LOCAL/Project/eece7205/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/pradnyeshchoudhari/EECE 7205 - LOCAL/Project/eece7205/lib/python3.8/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/pradnyeshchoudhari/EECE 7205 - LOCAL/Project/eece7205/lib/python3.8/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/pradnyeshchoudhari/EECE 7205 - LOCAL/Project/eece7205/lib/python3.8/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/pradnyeshchoudhari/EECE 7205 - LOCAL/Project/eece7205/lib/python3.8/site-packages (from requests->transformers) (2.2.3)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/Users/pradnyeshchoudhari/EECE 7205 - LOCAL/Project/eece7205/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[102], line 195\u001b[0m\n\u001b[1;32m    190\u001b[0m X_train, X_val, y_train, y_val \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[1;32m    191\u001b[0m     X, y_encoded, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[1;32m    192\u001b[0m )\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m--> 195\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# Make predictions on new data\u001b[39;00m\n\u001b[1;32m    198\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m DistilBertTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistilbert-base-uncased\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[100], line 54\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(X_train, y_train, X_val, y_val, n_epochs, batch_size, learning_rate)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m(X_train, y_train, X_val, y_val, n_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2e-5\u001b[39m):\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;66;03m# Initialize tokenizer and model\u001b[39;00m\n\u001b[1;32m     53\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m DistilBertTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistilbert-base-uncased\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 54\u001b[0m     model \u001b[38;5;241m=\u001b[39m BERTTagPredictor(n_tags\u001b[38;5;241m=\u001b[39m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;66;03m# Move model to GPU if available\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n",
    "        \"\"\"\n",
    "        Focal Loss implementation\n",
    "        \n",
    "        Args:\n",
    "            alpha (tensor): Weighting factor for each class, helps with class imbalance\n",
    "            gamma (float): Focusing parameter. Higher gamma reduces the loss for well-classified examples\n",
    "            reduction (str): 'mean' or 'sum'\n",
    "        \"\"\"\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        if alpha is not None:\n",
    "            self.alpha = torch.tensor(alpha)\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        \n",
    "        # Apply class weights if provided\n",
    "        if self.alpha is not None:\n",
    "            self.alpha = self.alpha.to(inputs.device)\n",
    "            at = self.alpha.gather(0, targets)\n",
    "            focal_loss = at * (1 - pt) ** self.gamma * ce_loss\n",
    "        else:\n",
    "            focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
    "        \n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        else:\n",
    "            return focal_loss.sum()\n",
    "\n",
    "class BERTTagPredictor(nn.Module):\n",
    "    def __init__(self, n_tags, dropout=0.3):\n",
    "        super(BERTTagPredictor, self).__init__()\n",
    "        self.bert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.classifier = nn.Linear(768, n_tags)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        return self.classifier(pooled_output)\n",
    "\n",
    "def calculate_class_weights(y_train):\n",
    "    \"\"\"Calculate class weights based on inverse frequency\"\"\"\n",
    "    classes, counts = np.unique(y_train, return_counts=True)\n",
    "    total_samples = len(y_train)\n",
    "    weights = total_samples / (len(classes) * counts)\n",
    "    return weights / weights.sum()  # Normalize weights\n",
    "\n",
    "# def train_model(X_train, y_train, X_val, y_val, n_epochs=5, batch_size=16, learning_rate=2e-5):\n",
    "#     tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "#     n_tags = len(np.unique(y_train))\n",
    "#     model = BERTTagPredictor(n_tags=n_tags)\n",
    "    \n",
    "#     # Calculate class weights for focal loss\n",
    "#     class_weights = calculate_class_weights(y_train)\n",
    "    \n",
    "#     # Initialize focal loss with class weights\n",
    "#     criterion = FocalLoss(alpha=class_weights, gamma=2.0)\n",
    "    \n",
    "#     device = 'cpu'\n",
    "#     model.to(device)\n",
    "#     criterion.to(device)\n",
    "    \n",
    "#     # Create datasets and dataloaders\n",
    "#     train_dataset = StackOverflowTagDataset(X_train, y_train, tokenizer)\n",
    "#     val_dataset = StackOverflowTagDataset(X_val, y_val, tokenizer)\n",
    "    \n",
    "#     train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "#     val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    \n",
    "#     optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "#     # Training loop\n",
    "#     best_val_acc = 0\n",
    "#     patience = 3\n",
    "#     patience_counter = 0\n",
    "    \n",
    "#     for epoch in range(n_epochs):\n",
    "#         model.train()\n",
    "#         total_loss = 0\n",
    "        \n",
    "#         for batch in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{n_epochs}'):\n",
    "#             optimizer.zero_grad()\n",
    "            \n",
    "#             input_ids = batch['input_ids'].to(device)\n",
    "#             attention_mask = batch['attention_mask'].to(device)\n",
    "#             tags = batch['tags'].to(device)\n",
    "            \n",
    "#             outputs = model(input_ids, attention_mask)\n",
    "#             loss = criterion(outputs, tags)\n",
    "            \n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "            \n",
    "#             total_loss += loss.item()\n",
    "        \n",
    "#         # Validation\n",
    "#         model.eval()\n",
    "#         val_predictions = []\n",
    "#         val_labels = []\n",
    "#         val_loss = 0\n",
    "        \n",
    "#         with torch.no_grad():\n",
    "#             for batch in val_loader:\n",
    "#                 input_ids = batch['input_ids'].to(device)\n",
    "#                 attention_mask = batch['attention_mask'].to(device)\n",
    "#                 tags = batch['tags'].to(device)\n",
    "                \n",
    "#                 outputs = model(input_ids, attention_mask)\n",
    "#                 val_loss += criterion(outputs, tags).item()\n",
    "                \n",
    "#                 _, predictions = torch.max(outputs, 1)\n",
    "#                 val_predictions.extend(predictions.cpu().numpy())\n",
    "#                 val_labels.extend(tags.cpu().numpy())\n",
    "        \n",
    "#         # Calculate metrics\n",
    "#         val_accuracy = accuracy_score(val_labels, val_predictions)\n",
    "#         val_report = classification_report(val_labels, val_predictions)\n",
    "        \n",
    "#         print(f'\\nEpoch {epoch + 1}:')\n",
    "#         print(f'Training loss: {total_loss / len(train_loader):.4f}')\n",
    "#         print(f'Validation loss: {val_loss / len(val_loader):.4f}')\n",
    "#         print(f'Validation Accuracy: {val_accuracy:.4f}')\n",
    "#         print('\\nClassification Report:')\n",
    "#         print(val_report)\n",
    "        \n",
    "#         # Early stopping with patience\n",
    "#         if val_accuracy > best_val_acc:\n",
    "#             best_val_acc = val_accuracy\n",
    "#             torch.save(model.state_dict(), 'best_model.pth')\n",
    "#             patience_counter = 0\n",
    "#         else:\n",
    "#             patience_counter += 1\n",
    "#             if patience_counter >= patience:\n",
    "#                 print(f'\\nEarly stopping triggered after {epoch + 1} epochs')\n",
    "#                 break\n",
    "    \n",
    "#     return model\n",
    "\n",
    "def predict_tags(model, texts, tokenizer, device):\n",
    "    \"\"\"Predict tags for new texts\"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    \n",
    "    dataset = StackOverflowTagDataset(texts, np.zeros(len(texts)), tokenizer)\n",
    "    dataloader = DataLoader(dataset, batch_size=16)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "    \n",
    "    return np.array(predictions)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Example of preparing your data:\n",
    "    # Assuming you have:\n",
    "    # X = [\"preprocessed text 1\", \"preprocessed text 2\", ...]\n",
    "    # y = [0, 1, 2, ...]  # Integer labels for each tag\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    \n",
    "    # Encode tags if they're not already integers\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y_encoded, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    model = train_model(X_train, y_train, X_val, y_val)\n",
    "    \n",
    "    # Make predictions on new data\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    new_texts = [\"example question 1\", \"example question 2\"]\n",
    "    predictions = predict_tags(model, new_texts, tokenizer, device)\n",
    "    \n",
    "    # Convert predictions back to original tag names\n",
    "    predicted_tags = label_encoder.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "class StackOverflowTagDataset(Dataset):\n",
    "    def __init__(self, texts, tags, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.tags = tags\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
    "            'tags': torch.tensor(self.tags[idx], dtype=torch.long)  # Changed to long for CrossEntropy\n",
    "        }\n",
    "\n",
    "class BERTTagPredictor(nn.Module):\n",
    "    def __init__(self, n_tags, dropout=0.3):\n",
    "        super(BERTTagPredictor, self).__init__()\n",
    "        self.bert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.classifier = nn.Linear(768, n_tags)  # 768 is BERT's hidden size\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]  # Use CLS token\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        return self.classifier(pooled_output)\n",
    "\n",
    "def train_model(X_train, y_train, X_val, y_val, n_epochs=5, batch_size=16, learning_rate=2e-5):\n",
    "    # Initialize tokenizer and model\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    n_tags = len(np.unique(y_train))\n",
    "    model = BERTTagPredictor(n_tags=n_tags)\n",
    "    \n",
    "    # Move model to GPU if available\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    \n",
    "    # Create datasets and dataloaders\n",
    "    train_dataset = StackOverflowTagDataset(X_train, y_train, tokenizer)\n",
    "    val_dataset = StackOverflowTagDataset(X_val, y_val, tokenizer)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    \n",
    "    # Initialize optimizer and loss function\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()  # Changed to CrossEntropyLoss\n",
    "    \n",
    "    # Training loop\n",
    "    best_val_acc = 0\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{n_epochs}'):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            tags = batch['tags'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, tags)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_predictions = []\n",
    "        val_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                tags = batch['tags']\n",
    "                \n",
    "                outputs = model(input_ids, attention_mask)\n",
    "                _, predictions = torch.max(outputs, 1)\n",
    "                \n",
    "                val_predictions.extend(predictions.cpu().numpy())\n",
    "                val_labels.extend(tags.numpy())\n",
    "        \n",
    "        # Calculate metrics\n",
    "        val_accuracy = accuracy_score(val_labels, val_predictions)\n",
    "        val_report = classification_report(val_labels, val_predictions)\n",
    "        \n",
    "        print(f'\\nEpoch {epoch + 1}:')\n",
    "        print(f'Average training loss: {total_loss / len(train_loader):.4f}')\n",
    "        print(f'Validation Accuracy: {val_accuracy:.4f}')\n",
    "        print('\\nClassification Report:')\n",
    "        print(val_report)\n",
    "        \n",
    "        # Save best model\n",
    "        if val_accuracy > best_val_acc:\n",
    "            best_val_acc = val_accuracy\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "    \n",
    "    return model\n",
    "\n",
    "def predict_tags(model, texts, tokenizer, device):\n",
    "    \"\"\"Predict tags for new texts\"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    \n",
    "    dataset = StackOverflowTagDataset(texts, np.zeros(len(texts)), tokenizer)\n",
    "    dataloader = DataLoader(dataset, batch_size=16)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "    \n",
    "    return np.array(predictions)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Example of preparing your data:\n",
    "    # Assuming you have:\n",
    "    # X = [\"preprocessed text 1\", \"preprocessed text 2\", ...]\n",
    "    # y = [0, 1, 2, ...]  # Integer labels for each tag\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    \n",
    "    # Encode tags if they're not already integers\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y_encoded, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    model = train_model(X_train, y_train, X_val, y_val)\n",
    "    \n",
    "    # Make predictions on new data\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    new_texts = [\"example question 1\", \"example question 2\"]\n",
    "    predictions = predict_tags(model, new_texts, tokenizer, device)\n",
    "    \n",
    "    # Convert predictions back to original tag names\n",
    "    predicted_tags = label_encoder.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:   0%|          | 0/625 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "text input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 208\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;66;03m# Example usage with your preprocessed data\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# Assuming you already have:\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;66;03m# X: your preprocessed text data\u001b[39;00m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;66;03m# y: your integer-encoded labels\u001b[39;00m\n\u001b[1;32m    206\u001b[0m     \n\u001b[1;32m    207\u001b[0m     \u001b[38;5;66;03m# Train the model directly with your data\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;66;03m# Make predictions on new data\u001b[39;00m\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(model, texts, tokenizer, device):\n",
      "Cell \u001b[0;32mIn[73], line 115\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(X, y, n_epochs, batch_size, learning_rate)\u001b[0m\n\u001b[1;32m    112\u001b[0m batch_labels \u001b[38;5;241m=\u001b[39m y_train[start_idx:end_idx]\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# Tokenize batch\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m encodings \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_texts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_length\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m    122\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# Move everything to device\u001b[39;00m\n\u001b[1;32m    125\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m encodings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/EECE 7205 - LOCAL/Project/eece7205/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:3021\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   3019\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   3020\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 3021\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3022\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3023\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[0;32m~/EECE 7205 - LOCAL/Project/eece7205/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:3081\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   3078\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   3080\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_valid_text_input(text):\n\u001b[0;32m-> 3081\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3082\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3083\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3084\u001b[0m     )\n\u001b[1;32m   3086\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_valid_text_input(text_pair):\n\u001b[1;32m   3087\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3088\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3089\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3090\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: text input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples)."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n",
    "        \"\"\"\n",
    "        Focal Loss implementation\n",
    "        \n",
    "        Args:\n",
    "            alpha (tensor): Weighting factor for each class, helps with class imbalance\n",
    "            gamma (float): Focusing parameter. Higher gamma reduces the loss for well-classified examples\n",
    "            reduction (str): 'mean' or 'sum'\n",
    "        \"\"\"\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        if alpha is not None:\n",
    "            self.alpha = torch.tensor(alpha)\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        \n",
    "        # Apply class weights if provided\n",
    "        if self.alpha is not None:\n",
    "            self.alpha = self.alpha.to(inputs.device)\n",
    "            at = self.alpha.gather(0, targets)\n",
    "            focal_loss = at * (1 - pt) ** self.gamma * ce_loss\n",
    "        else:\n",
    "            focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
    "        \n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        else:\n",
    "            return focal_loss.sum()\n",
    "\n",
    "class BERTTagPredictor(nn.Module):\n",
    "    def __init__(self, n_tags, dropout=0.3):\n",
    "        super(BERTTagPredictor, self).__init__()\n",
    "        self.bert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.classifier = nn.Linear(768, n_tags)  # 768 is BERT's hidden size\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]  # Use CLS token\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        return self.classifier(pooled_output)\n",
    "\n",
    "\n",
    "def train_model(X, y, n_epochs=5, batch_size=16, learning_rate=2e-5):\n",
    "    \"\"\"\n",
    "    Train model using preprocessed X and y data directly\n",
    "    \n",
    "    Args:\n",
    "        X_train: List/array of preprocessed text strings\n",
    "        y_train: Array of integer labels\n",
    "        X_val: List/array of preprocessed text strings\n",
    "        y_val: Array of integer labels\n",
    "    \"\"\"\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(y)\n",
    "    \n",
    "    # Convert y to numpy array if it's not already\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y\n",
    "    )\n",
    "\n",
    "\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    n_tags = len(np.unique(y_train))\n",
    "    model = BERTTagPredictor(n_tags=n_tags)\n",
    "    \n",
    "    # Calculate class weights for focal loss\n",
    "    class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "    criterion = FocalLoss(alpha=class_weights, gamma=2.0)\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    criterion.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Training loop\n",
    "    best_val_acc = 0\n",
    "    patience = 3\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        # Process training data in batches\n",
    "        num_batches = X_train.shape[0] // batch_size + (1 if X_train.shape[0] % batch_size != 0 else 0)\n",
    "        \n",
    "        for i in tqdm(range(num_batches), desc=f'Epoch {epoch + 1}/{n_epochs}'):\n",
    "            start_idx = i * batch_size\n",
    "            end_idx = min((i + 1) * batch_size, X_train.shape[0])\n",
    "            \n",
    "            # Get batch of texts and labels\n",
    "            batch_texts = X_train[start_idx:end_idx]\n",
    "            batch_labels = y_train[start_idx:end_idx]\n",
    "            \n",
    "            # Tokenize batch\n",
    "            encodings = tokenizer(\n",
    "                batch_texts,\n",
    "                add_special_tokens=True,\n",
    "                max_length=512,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            \n",
    "            # Move everything to device\n",
    "            input_ids = encodings['input_ids'].to(device)\n",
    "            attention_mask = encodings['attention_mask'].to(device)\n",
    "            labels = torch.tensor(batch_labels, dtype=torch.long).to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_predictions = []\n",
    "        val_loss = 0\n",
    "        \n",
    "        # Process validation data in batches\n",
    "        num_val_batches = X_val.shape[0] // batch_size + (1 if X_val.shape[0] % batch_size != 0 else 0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i in range(num_val_batches):\n",
    "                start_idx = i * batch_size\n",
    "                end_idx = min((i + 1) * batch_size, X_val.shape[0])\n",
    "                \n",
    "                # Get batch of texts and labels\n",
    "                batch_texts = X_val[start_idx:end_idx]\n",
    "                batch_labels = y_val[start_idx:end_idx]\n",
    "                \n",
    "                # Tokenize batch\n",
    "                encodings = tokenizer(\n",
    "                    batch_texts,\n",
    "                    add_special_tokens=True,\n",
    "                    max_length=512,\n",
    "                    padding='max_length',\n",
    "                    truncation=True,\n",
    "                    return_tensors='pt'\n",
    "                )\n",
    "                \n",
    "                input_ids = encodings['input_ids'].to(device)\n",
    "                attention_mask = encodings['attention_mask'].to(device)\n",
    "                labels = torch.tensor(batch_labels, dtype=torch.long).to(device)\n",
    "                \n",
    "                outputs = model(input_ids, attention_mask)\n",
    "                val_loss += criterion(outputs, labels).item()\n",
    "                \n",
    "                _, predictions = torch.max(outputs, 1)\n",
    "                val_predictions.extend(predictions.cpu().numpy())\n",
    "        \n",
    "        # Calculate metrics\n",
    "        val_accuracy = accuracy_score(y_val, val_predictions)\n",
    "        val_report = classification_report(y_val, val_predictions)\n",
    "        \n",
    "        print(f'\\nEpoch {epoch + 1}:')\n",
    "        print(f'Training loss: {total_loss / num_batches:.4f}')\n",
    "        print(f'Validation loss: {val_loss / num_val_batches:.4f}')\n",
    "        print(f'Validation Accuracy: {val_accuracy:.4f}')\n",
    "        print('\\nClassification Report:')\n",
    "        print(val_report)\n",
    "        \n",
    "        # Early stopping with patience\n",
    "        if val_accuracy > best_val_acc:\n",
    "            best_val_acc = val_accuracy\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f'\\nEarly stopping triggered after {epoch + 1} epochs')\n",
    "                break\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Example usage with your preprocessed data\n",
    "if __name__ == \"__main__\":\n",
    "    # Assuming you already have:\n",
    "    # X: your preprocessed text data\n",
    "    # y: your integer-encoded labels\n",
    "    \n",
    "    # Train the model directly with your data\n",
    "    model = train_model(X, y)\n",
    "    \n",
    "    # Make predictions on new data\n",
    "    def predict(model, texts, tokenizer, device):\n",
    "        model.eval()\n",
    "        predictions = []\n",
    "        \n",
    "        # Process in batches\n",
    "        batch_size = 16\n",
    "        num_batches = len(texts) // batch_size + (1 if len(texts) % batch_size != 0 else 0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i in range(num_batches):\n",
    "                start_idx = i * batch_size\n",
    "                end_idx = min((i + 1) * batch_size, len(texts))\n",
    "                batch_texts = texts[start_idx:end_idx]\n",
    "                \n",
    "                encodings = tokenizer(\n",
    "                    batch_texts,\n",
    "                    add_special_tokens=True,\n",
    "                    max_length=512,\n",
    "                    padding='max_length',\n",
    "                    truncation=True,\n",
    "                    return_tensors='pt'\n",
    "                )\n",
    "                \n",
    "                input_ids = encodings['input_ids'].to(device)\n",
    "                attention_mask = encodings['attention_mask'].to(device)\n",
    "                \n",
    "                outputs = model(input_ids, attention_mask)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                predictions.extend(preds.cpu().numpy())\n",
    "        \n",
    "        return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import scipy.sparse as sp\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = nn.CrossEntropyLoss(reduction='none')(inputs, targets)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * (1-pt)**self.gamma * ce_loss\n",
    "        return focal_loss.mean()\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        # Convert sparse matrix to dense numpy array if needed\n",
    "        if sp.issparse(texts):\n",
    "            self.texts = texts.toarray()\n",
    "        else:\n",
    "            self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.texts.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Convert numerical features to text format\n",
    "        # Assuming the features are meaningful numbers that we want to preserve\n",
    "        text = ' '.join(map(str, self.texts[idx]))\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "class DistilBERTClassifier(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        self.distilbert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(self.distilbert.config.hidden_size, n_classes)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.distilbert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0]  # Use [CLS] token\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        return self.classifier(pooled_output)\n",
    "\n",
    "def distilbertClassifierOut(X, y, save_path=None, batch_size=16, epochs=3, learning_rate=2e-5):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Label encoding\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(y)\n",
    "    n_classes = len(label_encoder.classes_)\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    print(f\"Training set shape: {X_train.shape}\")\n",
    "    print(f\"Test set shape: {X_test.shape}\")\n",
    "    \n",
    "    # Initialize tokenizer and model\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    model = DistilBERTClassifier(n_classes).to(device)\n",
    "    \n",
    "    # Create datasets and dataloaders\n",
    "    train_dataset = TextDataset(X_train, y_train, tokenizer)\n",
    "    test_dataset = TextDataset(X_test, y_test, tokenizer)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True,\n",
    "        num_workers=0  # Set to 0 for debugging\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=batch_size,\n",
    "        num_workers=0  # Set to 0 for debugging\n",
    "    )\n",
    "    \n",
    "    # Initialize optimizer and loss function\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    criterion = FocalLoss()\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f'Epoch {epoch+1}/{epochs}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}')\n",
    "        \n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Average Loss: {avg_loss:.4f}')\n",
    "    \n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Print classification report\n",
    "    print(\"\\nClassification Report:\\n\",\n",
    "          classification_report(all_labels, all_preds, \n",
    "                             target_names=label_encoder.classes_))\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=label_encoder.classes_,\n",
    "        yticklabels=label_encoder.classes_\n",
    "    )\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Save the model and tokenizer\n",
    "    if save_path:\n",
    "        model_dict = {\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"label_encoder\": label_encoder,\n",
    "            \"tokenizer\": tokenizer,\n",
    "        }\n",
    "        torch.save(model_dict, save_path)\n",
    "        print(f\"Model saved to {save_path}\")\n",
    "    \n",
    "    return model, tokenizer, label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Training set shape: (512, 1067)\n",
      "Test set shape: (128, 1067)\n",
      "Epoch 1/3, Batch 0/32, Loss: 1.0600\n",
      "Epoch 1/3, Batch 10/32, Loss: 0.9829\n",
      "Epoch 1/3, Batch 20/32, Loss: 1.1347\n",
      "Epoch 1/3, Batch 30/32, Loss: 1.0916\n",
      "Epoch 1/3, Average Loss: 1.0700\n",
      "Epoch 2/3, Batch 0/32, Loss: 1.0383\n",
      "Epoch 2/3, Batch 10/32, Loss: 0.9825\n",
      "Epoch 2/3, Batch 20/32, Loss: 1.0300\n",
      "Epoch 2/3, Batch 30/32, Loss: 1.0235\n",
      "Epoch 2/3, Average Loss: 1.0400\n",
      "Epoch 3/3, Batch 0/32, Loss: 1.0792\n",
      "Epoch 3/3, Batch 10/32, Loss: 1.1250\n",
      "Epoch 3/3, Batch 20/32, Loss: 1.0521\n",
      "Epoch 3/3, Batch 30/32, Loss: 1.0627\n",
      "Epoch 3/3, Average Loss: 1.0407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradnyeshchoudhari/EECE 7205 - LOCAL/Project/eece7205/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pradnyeshchoudhari/EECE 7205 - LOCAL/Project/eece7205/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pradnyeshchoudhari/EECE 7205 - LOCAL/Project/eece7205/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         CPP       0.00      0.00      0.00        26\n",
      "        Java       0.20      1.00      0.33        25\n",
      "  JavaScript       0.00      0.00      0.00        26\n",
      "      Python       0.00      0.00      0.00        26\n",
      "         SQL       0.00      0.00      0.00        25\n",
      "\n",
      "    accuracy                           0.20       128\n",
      "   macro avg       0.04      0.20      0.07       128\n",
      "weighted avg       0.04      0.20      0.06       128\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(DistilBERTClassifier(\n",
       "   (distilbert): DistilBertModel(\n",
       "     (embeddings): Embeddings(\n",
       "       (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "       (position_embeddings): Embedding(512, 768)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (transformer): Transformer(\n",
       "       (layer): ModuleList(\n",
       "         (0-5): 6 x TransformerBlock(\n",
       "           (attention): DistilBertSdpaAttention(\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "             (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "           )\n",
       "           (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (ffn): FFN(\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "             (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (activation): GELUActivation()\n",
       "           )\n",
       "           (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       "   (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       " ),\n",
       " DistilBertTokenizer(name_or_path='distilbert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       " \t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " },\n",
       " LabelEncoder())"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distilbertClassifierOut(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sp\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = nn.CrossEntropyLoss(reduction='none')(inputs, targets)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * (1-pt)**self.gamma * ce_loss\n",
    "        return focal_loss.mean()\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        if sp.issparse(texts):\n",
    "            self.texts = texts.toarray()\n",
    "        else:\n",
    "            self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.texts.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = ' '.join(map(str, self.texts[idx]))\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "class DistilBERTClassifier(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        self.distilbert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(self.distilbert.config.hidden_size, n_classes)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.distilbert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        return self.classifier(pooled_output)\n",
    "\n",
    "def distilbertClassifierOut(X, y, save_path=None, batch_size=128, epochs=2, learning_rate=2e-5):\n",
    "    start_time = time.time()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Label encoding\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(y)\n",
    "    n_classes = len(label_encoder.classes_)\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    print(f\"Training set shape: {X_train.shape}\")\n",
    "    print(f\"Test set shape: {X_test.shape}\")\n",
    "    print(f\"Number of classes: {n_classes}\")\n",
    "    \n",
    "    # Initialize tokenizer and model\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    model = DistilBERTClassifier(n_classes).to(device)\n",
    "    \n",
    "    # Create datasets and dataloaders\n",
    "    train_dataset = TextDataset(X_train, y_train, tokenizer)\n",
    "    test_dataset = TextDataset(X_test, y_test, tokenizer)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True,\n",
    "        num_workers=0\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=batch_size,\n",
    "        num_workers=0\n",
    "    )\n",
    "    \n",
    "    # Initialize optimizer and loss function\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    criterion = FocalLoss()\n",
    "    \n",
    "    print(f\"\\nStarting training at {datetime.now().strftime('%H:%M:%S')}\")\n",
    "    print(f\"Batch size: {batch_size}, Epochs: {epochs}\")\n",
    "    print(f\"Total batches per epoch: {len(train_loader)}\")\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start = time.time()\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            batch_start = time.time()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            if batch_idx % 5 == 0:  # Print every 5 batches\n",
    "                batch_time = time.time() - batch_start\n",
    "                print(f'Epoch {epoch+1}/{epochs} | Batch {batch_idx}/{len(train_loader)} | '\n",
    "                      f'Loss: {loss.item():.4f} | Batch time: {batch_time:.2f}s')\n",
    "        \n",
    "        epoch_time = time.time() - epoch_start\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f'Epoch {epoch+1}/{epochs} completed | Avg Loss: {avg_loss:.4f} | '\n",
    "              f'Time: {epoch_time:.2f}s')\n",
    "    \n",
    "    print(\"\\nEvaluating model...\")\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    print(\"\\nClassification Report:\\n\",\n",
    "          classification_report(all_labels, all_preds, \n",
    "                             target_names=label_encoder.classes_))\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=label_encoder.classes_,\n",
    "        yticklabels=label_encoder.classes_\n",
    "    )\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "    \n",
    "    if save_path:\n",
    "        model_dict = {\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"label_encoder\": label_encoder,\n",
    "            \"tokenizer\": tokenizer,\n",
    "        }\n",
    "        torch.save(model_dict, save_path)\n",
    "        print(f\"Model saved to {save_path}\")\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\nTotal training time: {total_time:.2f} seconds\")\n",
    "    \n",
    "    return model, tokenizer, label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Training set shape: (512, 1067)\n",
      "Test set shape: (128, 1067)\n",
      "Number of classes: 5\n",
      "\n",
      "Starting training at 08:35:39\n",
      "Batch size: 128, Epochs: 2\n",
      "Total batches per epoch: 4\n",
      "Epoch 1/2 | Batch 0/4 | Loss: 1.1117 | Batch time: 17.59s\n",
      "Epoch 1/2 completed | Avg Loss: 1.0569 | Time: 75.87s\n",
      "Epoch 2/2 | Batch 0/4 | Loss: 1.0455 | Batch time: 17.75s\n",
      "Epoch 2/2 completed | Avg Loss: 1.0402 | Time: 72.56s\n",
      "\n",
      "Evaluating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradnyeshchoudhari/EECE 7205 - LOCAL/Project/eece7205/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pradnyeshchoudhari/EECE 7205 - LOCAL/Project/eece7205/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pradnyeshchoudhari/EECE 7205 - LOCAL/Project/eece7205/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         CPP       0.20      1.00      0.34        26\n",
      "        Java       0.00      0.00      0.00        25\n",
      "  JavaScript       0.00      0.00      0.00        26\n",
      "      Python       0.00      0.00      0.00        26\n",
      "         SQL       0.00      0.00      0.00        25\n",
      "\n",
      "    accuracy                           0.20       128\n",
      "   macro avg       0.04      0.20      0.07       128\n",
      "weighted avg       0.04      0.20      0.07       128\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total training time: 154.28 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(DistilBERTClassifier(\n",
       "   (distilbert): DistilBertModel(\n",
       "     (embeddings): Embeddings(\n",
       "       (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "       (position_embeddings): Embedding(512, 768)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (transformer): Transformer(\n",
       "       (layer): ModuleList(\n",
       "         (0-5): 6 x TransformerBlock(\n",
       "           (attention): DistilBertSdpaAttention(\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "             (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "           )\n",
       "           (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (ffn): FFN(\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "             (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (activation): GELUActivation()\n",
       "           )\n",
       "           (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       "   (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       " ),\n",
       " DistilBertTokenizer(name_or_path='distilbert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       " \t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " },\n",
       " LabelEncoder())"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distilbertClassifierOut(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sp\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        if sp.issparse(texts):\n",
    "            self.texts = texts.toarray()\n",
    "        else:\n",
    "            self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.texts.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = ' '.join(map(str, self.texts[idx]))\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "class DistilBERTClassifier(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        self.distilbert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(self.distilbert.config.hidden_size, n_classes)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.distilbert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        return self.classifier(pooled_output)\n",
    "\n",
    "def distilbertClassifierOut(X, y, save_path='./notebooks', batch_size=32, epochs=5, learning_rate=2e-5):\n",
    "    start_time = time.time()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Label encoding\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(y)\n",
    "    n_classes = len(label_encoder.classes_)\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    print(f\"Training set shape: {X_train.shape}\")\n",
    "    print(f\"Test set shape: {X_test.shape}\")\n",
    "    print(f\"Number of classes: {n_classes}\")\n",
    "    \n",
    "    # Initialize tokenizer and model\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    model = DistilBERTClassifier(n_classes).to(device)\n",
    "    \n",
    "    # Create datasets and dataloaders\n",
    "    train_dataset = TextDataset(X_train, y_train, tokenizer)\n",
    "    test_dataset = TextDataset(X_test, y_test, tokenizer)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True,\n",
    "        num_workers=0\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=batch_size,\n",
    "        num_workers=0\n",
    "    )\n",
    "    \n",
    "    # Initialize optimizer and loss function\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    print(f\"\\nStarting training at {datetime.now().strftime('%H:%M:%S')}\")\n",
    "    print(f\"Batch size: {batch_size}, Epochs: {epochs}\")\n",
    "    print(f\"Total batches per epoch: {len(train_loader)}\")\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start = time.time()\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            batch_start = time.time()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            if batch_idx % 5 == 0:  # Print every 5 batches\n",
    "                batch_time = time.time() - batch_start\n",
    "                print(f'Epoch {epoch+1}/{epochs} | Batch {batch_idx}/{len(train_loader)} | '\n",
    "                      f'Loss: {loss.item():.4f} | Batch time: {batch_time:.2f}s')\n",
    "        \n",
    "        epoch_time = time.time() - epoch_start\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f'Epoch {epoch+1}/{epochs} completed | Avg Loss: {avg_loss:.4f} | '\n",
    "              f'Time: {epoch_time:.2f}s')\n",
    "    \n",
    "    print(\"\\nEvaluating model...\")\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    print(\"\\nClassification Report:\\n\",\n",
    "          classification_report(all_labels, all_preds, \n",
    "                             target_names=label_encoder.classes_))\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=label_encoder.classes_,\n",
    "        yticklabels=label_encoder.classes_\n",
    "    )\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "    \n",
    "    if save_path:\n",
    "        model_dict = {\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"label_encoder\": label_encoder,\n",
    "            \"tokenizer\": tokenizer,\n",
    "        }\n",
    "        torch.save(model_dict, save_path)\n",
    "        print(f\"Model saved to {save_path}\")\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\nTotal training time: {total_time:.2f} seconds\")\n",
    "    \n",
    "    return model, tokenizer, label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Training set shape: (512, 1067)\n",
      "Test set shape: (128, 1067)\n",
      "Number of classes: 5\n",
      "\n",
      "Starting training at 08:49:55\n",
      "Batch size: 32, Epochs: 5\n",
      "Total batches per epoch: 16\n",
      "Epoch 1/5 | Batch 0/16 | Loss: 1.5899 | Batch time: 3.77s\n",
      "Epoch 1/5 | Batch 5/16 | Loss: 1.6870 | Batch time: 2.32s\n",
      "Epoch 1/5 | Batch 10/16 | Loss: 1.6264 | Batch time: 2.45s\n",
      "Epoch 1/5 | Batch 15/16 | Loss: 1.5917 | Batch time: 2.59s\n",
      "Epoch 1/5 completed | Avg Loss: 1.6343 | Time: 48.00s\n",
      "Epoch 2/5 | Batch 0/16 | Loss: 1.6352 | Batch time: 2.98s\n",
      "Epoch 2/5 | Batch 5/16 | Loss: 1.6303 | Batch time: 2.46s\n",
      "Epoch 2/5 | Batch 10/16 | Loss: 1.6412 | Batch time: 2.44s\n",
      "Epoch 2/5 | Batch 15/16 | Loss: 1.6225 | Batch time: 2.57s\n",
      "Epoch 2/5 completed | Avg Loss: 1.6190 | Time: 47.61s\n",
      "Epoch 3/5 | Batch 0/16 | Loss: 1.6474 | Batch time: 2.71s\n",
      "Epoch 3/5 | Batch 5/16 | Loss: 1.6348 | Batch time: 2.59s\n",
      "Epoch 3/5 | Batch 10/16 | Loss: 1.6210 | Batch time: 2.70s\n",
      "Epoch 3/5 | Batch 15/16 | Loss: 1.6054 | Batch time: 2.97s\n",
      "Epoch 3/5 completed | Avg Loss: 1.6149 | Time: 49.34s\n",
      "Epoch 4/5 | Batch 0/16 | Loss: 1.6075 | Batch time: 2.48s\n",
      "Epoch 4/5 | Batch 5/16 | Loss: 1.6223 | Batch time: 2.45s\n",
      "Epoch 4/5 | Batch 10/16 | Loss: 1.6121 | Batch time: 2.51s\n",
      "Epoch 4/5 | Batch 15/16 | Loss: 1.5887 | Batch time: 2.58s\n",
      "Epoch 4/5 completed | Avg Loss: 1.6101 | Time: 46.33s\n",
      "Epoch 5/5 | Batch 0/16 | Loss: 1.6424 | Batch time: 2.69s\n",
      "Epoch 5/5 | Batch 5/16 | Loss: 1.5882 | Batch time: 2.61s\n",
      "Epoch 5/5 | Batch 10/16 | Loss: 1.6361 | Batch time: 2.84s\n",
      "Epoch 5/5 | Batch 15/16 | Loss: 1.5942 | Batch time: 2.81s\n",
      "Epoch 5/5 completed | Avg Loss: 1.6206 | Time: 51.13s\n",
      "\n",
      "Evaluating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradnyeshchoudhari/EECE 7205 - LOCAL/Project/eece7205/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pradnyeshchoudhari/EECE 7205 - LOCAL/Project/eece7205/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pradnyeshchoudhari/EECE 7205 - LOCAL/Project/eece7205/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         CPP       0.33      0.12      0.17        26\n",
      "        Java       0.00      0.00      0.00        25\n",
      "  JavaScript       0.21      0.96      0.34        26\n",
      "      Python       0.00      0.00      0.00        26\n",
      "         SQL       0.00      0.00      0.00        25\n",
      "\n",
      "    accuracy                           0.22       128\n",
      "   macro avg       0.11      0.22      0.10       128\n",
      "weighted avg       0.11      0.22      0.10       128\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./notebooks\n",
      "\n",
      "Total training time: 248.01 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(DistilBERTClassifier(\n",
       "   (distilbert): DistilBertModel(\n",
       "     (embeddings): Embeddings(\n",
       "       (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "       (position_embeddings): Embedding(512, 768)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (transformer): Transformer(\n",
       "       (layer): ModuleList(\n",
       "         (0-5): 6 x TransformerBlock(\n",
       "           (attention): DistilBertSdpaAttention(\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "             (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "           )\n",
       "           (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (ffn): FFN(\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "             (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (activation): GELUActivation()\n",
       "           )\n",
       "           (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       "   (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       " ),\n",
       " DistilBertTokenizer(name_or_path='distilbert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       " \t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " },\n",
       " LabelEncoder())"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tfidf.fit_transform(df_labeled[\"Processed_Text\"])\n",
    "y = df_labeled[\"Label\"]\n",
    "distilbertClassifierOut(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "n_classes = len(label_encoder.classes_)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[116], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m TextDataset(X_train, y_train, \u001b[43mtokenizer\u001b[49m)\n\u001b[1;32m      2\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m TextDataset(X_test, y_test, tokenizer)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "train_dataset = TextDataset(X_train, y_train, tokenizer)\n",
    "test_dataset = TextDataset(X_test, y_test, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[117], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenize_data\u001b[39m(X_train):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer(X_train, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 9\u001b[0m tokenized_train \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241m.\u001b[39mmap(tokenize_data, batched\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m tokenized_test \u001b[38;5;241m=\u001b[39m test_dataset\u001b[38;5;241m.\u001b[39mmap(tokenize_data, batched\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def tokenize_data(X_train):\n",
    "    return tokenizer(X_train, truncation=True)\n",
    "\n",
    "tokenized_train = train_dataset.map(tokenize_data, batched=True)\n",
    "tokenized_test = test_dataset.map(tokenize_data, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries needed\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import DistilBertModel, DistilBertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 512\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 2\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 1e-05\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Triage(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        title = str(self.data.TITLE[index])\n",
    "        title = \" \".join(title.split())\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            title,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.data.ENCODE_CAT[index], dtype=torch.long)\n",
    "        } \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse._csr.csr_matrix"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_labeled['Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (640,)\n",
      "TRAIN Dataset: (512,)\n",
      "TEST Dataset: (128,)\n"
     ]
    }
   ],
   "source": [
    "# Creating the dataset and dataloader for the neural network\n",
    "df = X\n",
    "train_size = 0.8\n",
    "train_dataset=df.sample(frac=train_size,random_state=200)\n",
    "test_dataset=df.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(df.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "training_set = Triage(train_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = Triage(test_dataset, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the customized model, by adding a drop out and a dense layer on top of distil bert to get the final output for the model. \n",
    "\n",
    "class DistillBERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DistillBERTClass, self).__init__()\n",
    "        self.l1 = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.classifier = torch.nn.Linear(768, 4)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        pooler = self.pre_classifier(pooler)\n",
    "        pooler = torch.nn.ReLU()(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "        output = self.classifier(pooler)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistillBERTClass(\n",
       "  (l1): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DistillBERTClass()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the loss function and optimizer\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calcuate the accuracy of the model\n",
    "\n",
    "def calcuate_accu(big_idx, targets):\n",
    "    n_correct = (big_idx==targets).sum().item()\n",
    "    return n_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = TRAIN_BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train, y_train, epoch):\n",
    "    tr_loss = 0\n",
    "    n_correct = 0\n",
    "    nb_tr_steps = 0\n",
    "    nb_tr_examples = 0\n",
    "    model.train()\n",
    "    \n",
    "    # Loop through each batch in X_train and y_train\n",
    "    for i in range(0, X_train.shape[0], batch_size):\n",
    "        # Select the batch data\n",
    "        ids = X_train[i:i + batch_size].to(device, dtype=torch.long)\n",
    "        targets = y_train[i:i + batch_size].to(device, dtype=torch.long)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(ids)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        \n",
    "        # Accumulate loss and calculate accuracy\n",
    "        tr_loss += loss.item()\n",
    "        big_val, big_idx = torch.max(outputs.data, dim=1)\n",
    "        n_correct += calculate_accu(big_idx, targets)\n",
    "        \n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples += targets.size(0)\n",
    "        \n",
    "        # Logging every 5000 steps\n",
    "        if i % 5000 == 0:\n",
    "            loss_step = tr_loss / nb_tr_steps\n",
    "            accu_step = (n_correct * 100) / nb_tr_examples\n",
    "            print(f\"Training Loss per 5000 steps: {loss_step}\")\n",
    "            print(f\"Training Accuracy per 5000 steps: {accu_step}\")\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Epoch results\n",
    "    epoch_loss = tr_loss / nb_tr_steps\n",
    "    epoch_accu = (n_correct * 100) / nb_tr_examples\n",
    "    print(f\"The Total Accuracy for Epoch {epoch}: {epoch_accu}\")\n",
    "    print(f\"Training Loss Epoch: {epoch_loss}\")\n",
    "    print(f\"Training Accuracy Epoch: {epoch_accu}\")\n",
    "\n",
    "    return epoch_loss, epoch_accu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "to not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[150], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[149], line 11\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(X_train, y_train, epoch)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Loop through each batch in X_train and y_train\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], batch_size):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Select the batch data\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     ids \u001b[38;5;241m=\u001b[39m \u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m(device, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m     12\u001b[0m     targets \u001b[38;5;241m=\u001b[39m y_train[i:i \u001b[38;5;241m+\u001b[39m batch_size]\u001b[38;5;241m.\u001b[39mto(device, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n",
      "File \u001b[0;32m~/EECE 7205 - LOCAL/Project/eece7205/lib/python3.8/site-packages/scipy/sparse/_base.py:771\u001b[0m, in \u001b[0;36mspmatrix.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetnnz()\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 771\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(attr \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m not found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: to not found"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    train(X_train, y_train, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
